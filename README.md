# Machine-Learning-Assignment

## Information
We use Python libraries(Pandas, nltk(Natural Language Toolkit), re(Regular Expression)) to developed this project.

We use nltk(Natural Language Toolkit) to perform these tasks:
* Tokenization (Tokenization is a way of separating a piece of text into smaller units called tokens.)
* Removing stopwords (eliminate words that are so commonly used that they carry very little useful information.)
* Stemming (Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma)
